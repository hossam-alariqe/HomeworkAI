#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import pickle

# ---------------------------
# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ---------------------------
df = pd.read_csv(r"C:\Users\ComputerWorld\Desktop\Tweets.csv")

# ÙÙ‚Ø· Ù†Ø­ØªØ§Ø¬ Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØªØµÙ†ÙŠÙ
df = df[['airline_sentiment', 'text']].dropna()
df = df.rename(columns={'airline_sentiment': 'sentiment', 'text': 'text'})

# ---------------------------
# 2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
# ---------------------------
def clean_text(s):
    s = str(s)
    s = re.sub(r"http\S+", " ", s)       # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    s = re.sub(r"@\w+", " ", s)          # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù†Ø´Ù†
    s = re.sub(r"[^A-Za-z0-9\s]", " ", s) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø§ØµØ©
    s = re.sub(r"\s+", " ", s).strip()
    return s.lower()

df['text_clean'] = df['text'].apply(clean_text)

# ---------------------------
# 3. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ---------------------------
X = df['text_clean'].values
y = df['sentiment'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ---------------------------
# 4. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…ÙŠØ²Ø§Øª (TF-IDF)
# ---------------------------
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# ---------------------------
# 5. ØªØ¯Ø±ÙŠØ¨ Naive Bayes
# ---------------------------
clf = MultinomialNB(alpha=1.0)
clf.fit(X_train_vec, y_train)

# ---------------------------
# 6. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
# ---------------------------
y_pred = clf.predict(X_test_vec)

print("âœ… Ø§Ù„Ø¯Ù‚Ø©:", accuracy_score(y_test, y_pred))
print("\nðŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:\n", classification_report(y_test, y_pred))
print("\nðŸ“Š Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³:\n", confusion_matrix(y_test, y_pred))

# ---------------------------
# 7. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¬Ù…Ù„ Ø¬Ø¯ÙŠØ¯Ø©
# ---------------------------
examples = [
    "I love this airline, they were so helpful!",
    "My flight was delayed and the staff was rude.",
    "The flight was okay, nothing special."
]
examples_clean = [clean_text(t) for t in examples]
examples_vec = vectorizer.transform(examples_clean)
preds = clf.predict(examples_vec)

print("\nðŸ”® ØªÙ†Ø¨Ø¤Ø§Øª Ø£Ù…Ø«Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©:")
for text, p in zip(examples, preds):
    print(f" - '{text}' => {p}")



# In[ ]:




